{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_baseline.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN0cFIwdw4VkjF5bM2eh/Lx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VinhDevNguyen/Project_Alpha/blob/RNN_baseline/RNN_baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kx8s3aDhnIi4"
      },
      "source": [
        "# Mount Google Drive\r\n",
        "Data for ``Booking Challenge`` stores in ``UIT TSP``folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DAtPRJUnHqj",
        "outputId": "47ddc4bf-0a4f-43b7-8863-9d92f533f828"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1dpK2JuomBa"
      },
      "source": [
        "# Data path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQYdX28EpKBX"
      },
      "source": [
        "folder_path = './drive/MyDrive/UIT-TSP/Booking.com Data Challenge'\r\n",
        "data_path = \"/content/drive/MyDrive/UIT-TSP/Booking.com Data Challenge/booking_train_set.csv\""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Xg633w0mF5l"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Zgx_TCvi7I4"
      },
      "source": [
        "import math\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ee9SYN0fmVOe"
      },
      "source": [
        "# RNN "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rth6exvGmS-Y"
      },
      "source": [
        "class RNNModel(nn.Module):\r\n",
        "    \"\"\"Container module with an encoder, a recurrent module, and a decoder.\"\"\"\r\n",
        "\r\n",
        "    def __init__(self, \r\n",
        "                 vocab_size, \r\n",
        "                 emb_size=500, \r\n",
        "                 rnn_dim=500, \r\n",
        "                 n_layers=2, \r\n",
        "                 dropout=0.3, \r\n",
        "                 rnn_dropout=0.3, \r\n",
        "                 tie_weights=False):\r\n",
        "        super(RNNModel, self).__init__()\r\n",
        "        self.drop = nn.Dropout(dropout) \r\n",
        "        self.embedding = nn.Embedding(vocab_size,emb_dim) \r\n",
        "        self.rnn = nn.RNN(input_size=emb_dim,\r\n",
        "                          hidden_size=rnn_dim, \r\n",
        "                          num_layers=n_layers, \r\n",
        "                          dropout=rnn_dropout) \r\n",
        "        self.dense = nn.Linear(rnn_dim,vocab_size)\r\n",
        "\r\n",
        "        # Optionally tie weights as in:\r\n",
        "        # \"Using the Output Embedding to Improve Language Models\" (Press & Wolf 2016)\r\n",
        "        # https://arxiv.org/abs/1608.05859\r\n",
        "        # and\r\n",
        "        # \"Tying Word Vectors and Word Classifiers: A Loss Framework for Language Modeling\" (Inan et al. 2016)\r\n",
        "        # https://arxiv.org/abs/1611.01462\r\n",
        "        if tie_weights: # theta_d = theta_y\r\n",
        "          self.dense.weight = self.embedding.weight\r\n",
        "\r\n",
        "        self.vocab_size = vocab_size \r\n",
        "        self.emb_size = emb_size \r\n",
        "        self.rnn_dim = rnn_dim \r\n",
        "        self.n_layers = n_layers \r\n",
        "        self.dropout = dropout \r\n",
        "        self.rnn_dropout = rnn_dropout \r\n",
        "        self.tie_weights = tie_weights \r\n",
        "\r\n",
        "\r\n",
        "    # def init_weights(self):\r\n",
        "    #     initrange = 0.1\r\n",
        "    #     nn.init.uniform_(self.encoder.weight, -initrange, initrange)\r\n",
        "    #     nn.init.zeros_(self.decoder.weight)\r\n",
        "    #     nn.init.uniform_(self.decoder.weight, -initrange, initrange)\r\n",
        "\r\n",
        "    # Not clear here \r\n",
        "    def forward(self, input, h0=None): \r\n",
        "      out, hidden = self.rnn(\r\n",
        "                      self.drop(\r\n",
        "                          self.embedding(input)),\r\n",
        "                      h0)\r\n",
        "      out = self.dense(self.drop(\r\n",
        "                            out.view(\r\n",
        "                                out.size(0)*out.size(1),\r\n",
        "                                out.size(2)))\r\n",
        "                      )\r\n",
        "      return out, hidden \r\n",
        "\r\n",
        "    # def forward(self, input, hidden):\r\n",
        "    #     emb = self.drop(self.encoder(input))\r\n",
        "    #     output, hidden = self.rnn(emb, hidden)\r\n",
        "    #     output = self.drop(output)\r\n",
        "    #     decoded = self.decoder(output)\r\n",
        "    #     decoded = decoded.view(-1, self.ntoken)\r\n",
        "    #     return F.log_softmax(decoded, dim=1), hidden\r\n",
        "\r\n",
        "    # def init_hidden(self, bsz):\r\n",
        "    #     weight = next(self.parameters())\r\n",
        "    #     if self.rnn_type == 'LSTM':\r\n",
        "    #         return (weight.new_zeros(self.nlayers, bsz, self.nhid),\r\n",
        "    #                 weight.new_zeros(self.nlayers, bsz, self.nhid))\r\n",
        "    #     else:\r\n",
        "    #         return weight.new_zeros(self.nlayers, bsz, self.nhid)\r\n",
        "\r\n",
        "    # def save_model(self): \r\n",
        "\r\n",
        "    # def load_model(self): \r\n",
        "\r\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrQPL3bo-JtU"
      },
      "source": [
        "def "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5Q4_aSfpb10"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}