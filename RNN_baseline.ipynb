{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_baseline.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM6yQayH5heRdEQn2IsY1kw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VinhDevNguyen/Project_Alpha/blob/RNN_baseline/RNN_baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kx8s3aDhnIi4"
      },
      "source": [
        "# Mount Google Drive\r\n",
        "Data for ``Booking Challenge`` stores in ``UIT TSP``folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DAtPRJUnHqj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Xg633w0mF5l"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Zgx_TCvi7I4"
      },
      "source": [
        "import math\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ee9SYN0fmVOe"
      },
      "source": [
        "# RNN "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rth6exvGmS-Y"
      },
      "source": [
        "class RNNModel(nn.Module):\r\n",
        "    \"\"\"Container module with an encoder, a recurrent module, and a decoder.\"\"\"\r\n",
        "\r\n",
        "    def __init__(self, \r\n",
        "                 rnn_type, \r\n",
        "                 ntoken, \r\n",
        "                 ninp, \r\n",
        "                 nhid, \r\n",
        "                 nlayers, \r\n",
        "                 dropout=0.5, \r\n",
        "                 tie_weights=False):\r\n",
        "        super(RNNModel, self).__init__()\r\n",
        "        self.ntoken = ntoken\r\n",
        "        self.drop = nn.Dropout(dropout)\r\n",
        "        self.encoder = nn.Embedding(ntoken, ninp)\r\n",
        "        if rnn_type in ['LSTM', 'GRU']:\r\n",
        "            self.rnn = getattr(nn, rnn_type)(ninp, nhid, nlayers, dropout=dropout)\r\n",
        "        else:\r\n",
        "            try:\r\n",
        "                nonlinearity = {'RNN_TANH': 'tanh', 'RNN_RELU': 'relu'}[rnn_type]\r\n",
        "            except KeyError:\r\n",
        "                raise ValueError( \"\"\"An invalid option for `--model` was supplied,\r\n",
        "                                 options are ['LSTM', 'GRU', 'RNN_TANH' or 'RNN_RELU']\"\"\")\r\n",
        "            self.rnn = nn.RNN(ninp, nhid, nlayers, nonlinearity=nonlinearity, dropout=dropout)\r\n",
        "        self.decoder = nn.Linear(nhid, ntoken)\r\n",
        "\r\n",
        "        # Optionally tie weights as in:\r\n",
        "        # \"Using the Output Embedding to Improve Language Models\" (Press & Wolf 2016)\r\n",
        "        # https://arxiv.org/abs/1608.05859\r\n",
        "        # and\r\n",
        "        # \"Tying Word Vectors and Word Classifiers: A Loss Framework for Language Modeling\" (Inan et al. 2016)\r\n",
        "        # https://arxiv.org/abs/1611.01462\r\n",
        "        if tie_weights:\r\n",
        "            if nhid != ninp:\r\n",
        "                raise ValueError('When using the tied flag, nhid must be equal to emsize')\r\n",
        "            self.decoder.weight = self.encoder.weight\r\n",
        "\r\n",
        "        self.init_weights()\r\n",
        "\r\n",
        "        self.rnn_type = rnn_type\r\n",
        "        self.nhid = nhid\r\n",
        "        self.nlayers = nlayers\r\n",
        "\r\n",
        "    def init_weights(self):\r\n",
        "        initrange = 0.1\r\n",
        "        nn.init.uniform_(self.encoder.weight, -initrange, initrange)\r\n",
        "        nn.init.zeros_(self.decoder.weight)\r\n",
        "        nn.init.uniform_(self.decoder.weight, -initrange, initrange)\r\n",
        "\r\n",
        "    def forward(self, input, hidden):\r\n",
        "        emb = self.drop(self.encoder(input))\r\n",
        "        output, hidden = self.rnn(emb, hidden)\r\n",
        "        output = self.drop(output)\r\n",
        "        decoded = self.decoder(output)\r\n",
        "        decoded = decoded.view(-1, self.ntoken)\r\n",
        "        return F.log_softmax(decoded, dim=1), hidden\r\n",
        "\r\n",
        "    def init_hidden(self, bsz):\r\n",
        "        weight = next(self.parameters())\r\n",
        "        if self.rnn_type == 'LSTM':\r\n",
        "            return (weight.new_zeros(self.nlayers, bsz, self.nhid),\r\n",
        "                    weight.new_zeros(self.nlayers, bsz, self.nhid))\r\n",
        "        else:\r\n",
        "            return weight.new_zeros(self.nlayers, bsz, self.nhid)\r\n",
        "\r\n",
        "    # def save_model(self): \r\n",
        "    # def load_model(self): \r\n",
        "\r\n"
      ],
      "execution_count": 2,
      "outputs": []
    }
  ]
}